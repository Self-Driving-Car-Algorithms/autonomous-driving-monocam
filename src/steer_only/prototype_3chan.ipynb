{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def image_preprocessing(img):\n",
    "    \"\"\"preproccesing training data to keep only S channel in HSV color space, and resize to 16X32\"\"\"\n",
    "\n",
    "    resized = cv2.resize((cv2.cvtColor(img, cv2.COLOR_RGB2HSV))[:,:,:],(img_cols,img_rows))\n",
    "    return resized\n",
    "\n",
    "def extract(i):\n",
    "    X_ = []\n",
    "    y_ = []\n",
    "\n",
    "    img_path = logs[i][0]\n",
    "    img_path = data_folder+'IMG'+(img_path.split('IMG')[1]).strip()\n",
    "    img = plt.imread(img_path)\n",
    "    X_.append(image_preprocessing(img))\n",
    "    y_.append(float(logs[i][3]))\n",
    "\n",
    "    img_path = logs[i][1]\n",
    "    img_path = data_folder+'IMG'+(img_path.split('IMG')[1]).strip()\n",
    "    img = plt.imread(img_path)\n",
    "    X_.append(image_preprocessing(img))\n",
    "    y_.append(float(logs[i][3]) + delta_)\n",
    "\n",
    "    img_path = logs[i][2]\n",
    "    img_path = data_folder+'IMG'+(img_path.split('IMG')[1]).strip()\n",
    "    img = plt.imread(img_path)\n",
    "    X_.append(image_preprocessing(img))\n",
    "    y_.append(float(logs[i][3]) - delta_)\n",
    "\n",
    "    return X_, y_\n",
    "\n",
    "def load_data(X,y,data_folder,delta=0.08):\n",
    "    \"\"\"function to load training data\"\"\"\n",
    "\n",
    "    global logs\n",
    "    global delta_\n",
    "\n",
    "    delta_ = delta\n",
    "\n",
    "    log_path = data_folder + 'driving_log.csv'\n",
    "    logs = []\n",
    "\n",
    "    # load logs\n",
    "    with open(log_path,'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in reader:\n",
    "            logs.append(line)\n",
    "        log_labels = logs.pop(0)\n",
    "\n",
    "    pool = Pool(processes=6)\n",
    "\n",
    "    for X_, y_ in tqdm(pool.imap_unordered(extract, range(len(logs))), total=len(logs)):\n",
    "        X.extend(X_)\n",
    "        y.extend(y_)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 120\n",
    "img_cols = 240\n",
    "\n",
    "#data path\n",
    "data_folder = '../../data/udacity_official/'\n",
    "\n",
    "#batch size and epoch\n",
    "batch_size=128\n",
    "nb_epoch=7\n",
    "\n",
    "data={}\n",
    "data['features'] = []\n",
    "data['labels'] = []\n",
    "\n",
    "load_data(data['features'], data['labels'], data_folder, 0.3)\n",
    "\n",
    "X_train = np.array(data['features']).astype('float32')\n",
    "y_train = np.array(data['labels']).astype('float32')\n",
    "\n",
    "\n",
    "# horizonal reflection to agument the data\n",
    "X_train = np.append(X_train, X_train[:,:,::-1,:], axis=0)\n",
    "y_train = np.append(y_train, -y_train, axis=0)\n",
    "\n",
    "# split train and validation\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0, test_size=0.1)\n",
    "\n",
    "# reshape to have correct dimension\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Lambda, Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Cropping2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "print(\"\\nBuilding and compiling the model ...\")\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1.0, input_shape=(img_rows, img_cols, 3)))\n",
    "# Block - conv\n",
    "model.add(Convolution2D(2, 11, 11, border_mode='valid', subsample=[2, 2], init='glorot_uniform', activation='relu', name='Conv1'))\n",
    "# Block - conv\n",
    "model.add(Convolution2D(1, 5, 5, border_mode='valid', subsample=[2, 2], init='glorot_uniform', activation='relu', name='Conv2'))\n",
    "# Block - conv\n",
    "model.add(Convolution2D(1, 3, 3, border_mode='valid', subsample=[2, 2], init='glorot_uniform', activation='relu', name='Conv3'))\n",
    "# Block - conv\n",
    "#model.add(Convolution2D(1, 3, 3, border_mode='valid', init='glorot_uniform', activation='relu', name='Conv4'))\n",
    "# Block - flatten\n",
    "#model.add(MaxPooling2D((4,4),(4,4),'valid', name='pool1'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, name='output')) \n",
    "model.summary()\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_FACTOR = 1\n",
    "nb_epoch=20\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import math\n",
    "\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='../../data/logs/steer_only/', histogram_freq=1, \n",
    "                                          write_graph=True, write_images=True)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"../../data/weights/steer_only/model.h5\", monitor='val_loss', verbose=0, \n",
    "                                             save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    " \n",
    "history = model.fit(X_train, y_train, \n",
    "                  batch_size=batch_size,\n",
    "                  nb_epoch=nb_epoch, verbose=1,\n",
    "                  validation_data=(X_val, y_val))\n",
    "\n",
    "print(\"\\nTraining the model ended.\")\n",
    "\n",
    "print(\"\\nSaving Model...\")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"../../data/weights/steer_only/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"../../data/weights/steer_only/model.h5\")\n",
    "print(\"Model Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSaving Model...\")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"../../data/weights/steer_only/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"../../data/weights/steer_only/model.h5\")\n",
    "print(\"Model Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

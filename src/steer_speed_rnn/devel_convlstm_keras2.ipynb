{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "DATASET_PATH = \"../../data/udacity_sim_data/\"\n",
    "VAL_PATH = \"../../data/track1/seq1/\"\n",
    "def load_dataset(file_path):\n",
    "    '''\n",
    "    Loads dataset in memory\n",
    "    '''\n",
    "    dataset = []\n",
    "    with open(file_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            try:\n",
    "                dataset.append({'center':line[0], 'left':line[1], 'right':line[2], 'steering':float(line[3]), \n",
    "                            'throttle':float(line[4]), 'brake':float(line[5]), 'speed':float(line[6])/15.0 - 1})\n",
    "            except:\n",
    "                continue\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset(os.path.join(DATASET_PATH, \"driving_log.csv\"))\n",
    "val_dataset = load_dataset(os.path.join(VAL_PATH, \"driving_log.csv\"))\n",
    "\n",
    "print(\"Loaded {} samples from file {}\".format(len(dataset),DATASET_PATH))\n",
    "print(\"Loaded {} samples from file {}\".format(len(val_dataset),VAL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sample_file = os.path.join(DATASET_PATH, dataset[0]['center'].strip())\n",
    "INPUT_IMAGE_ROWS, INPUT_IMAGE_COLS, INPUT_IMAGE_CHANNELS = 160, 320, 3\n",
    "rows, cols = 160, 320\n",
    "\n",
    "seq_len = 5\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "train_set = dataset\n",
    "valid_set = val_dataset\n",
    "\n",
    "print(\"train set has {} elements\".format(len(train_set)))\n",
    "print(\"valid set has {} elements\".format(len(valid_set)))\n",
    "\n",
    "def data_generator(path, dataset, seq_len):\n",
    "    batch_seq_images = np.zeros((BATCH_SIZE, seq_len, 160, 320, 3))\n",
    "    batch_seq_speed = np.zeros((BATCH_SIZE, seq_len, 1))\n",
    "    \n",
    "    while 1:\n",
    "        for i in range(BATCH_SIZE):\n",
    "            while 1:\n",
    "                index = np.random.randint(len(dataset))\n",
    "                if index + seq_len <= len(dataset):\n",
    "                    seq_speed = []\n",
    "                    seq_images = []\n",
    "                    for j in range(index, index + seq_len):\n",
    "                        seq_speed.append(dataset[j][\"speed\"])\n",
    "                        img = cv2.imread(path + dataset[j][\"center\"].strip())\n",
    "                        #img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)[:, :, 1]\n",
    "                        #img = np.asarray(img).reshape(160, 320, 1)\n",
    "                        seq_images.append(img)\n",
    "                    seq_speed = np.array(seq_speed)\n",
    "                    seq_images = np.array(seq_images)\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            batch_seq_images[i] = seq_images\n",
    "            batch_seq_speed[i] = seq_speed.reshape(seq_len, 1)\n",
    "            #batch_seq_steering_angles[i] = seq_steering_angles\n",
    "\n",
    "        # for ru\n",
    "        yield batch_seq_images, batch_seq_speed[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model from scratch\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Lambda, Dense, Activation, Flatten, Dropout\n",
    "#from keras.layers.convolutional import Cropping2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers import GRU, LSTM, Conv2D, ConvLSTM2D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "print(\"\\nBuilding and compiling the model ...\")\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(TimeDistributed(Lambda(lambda x: (x / 127.5) - 1.0), input_shape=(None, INPUT_IMAGE_ROWS, INPUT_IMAGE_COLS, INPUT_IMAGE_CHANNELS)))\n",
    "# Block - conv\n",
    "model.add(TimeDistributed(Conv2D(8, (11, 11), padding='valid', strides=(2, 2), kernel_initializer='glorot_uniform', activation='relu', name='Conv1')))\n",
    "# Block - conv\n",
    "model.add(TimeDistributed(Conv2D(16, (5, 5), padding='valid', strides=(2, 2), kernel_initializer='glorot_uniform', activation='relu', name='Conv2')))\n",
    "# Block - conv\n",
    "model.add(TimeDistributed(Conv2D(16, (5, 5), padding='valid', strides=(2, 2), kernel_initializer='glorot_uniform', activation='relu', name='Conv3')))\n",
    "# Block - conv\n",
    "\n",
    "model.add(ConvLSTM2D(16, (5, 5), strides=(1, 1), activation='relu', recurrent_activation='relu', kernel_initializer='glorot_uniform',\n",
    "         recurrent_initializer='glorot_uniform', padding='valid', return_sequences=False, name='convlstm'))\n",
    "model.add(Conv2D(16, (3, 3), padding='valid', kernel_initializer='glorot_uniform', activation='relu', name='Conv4'))\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(256, name='fc'))\n",
    "model.add(Dense(1, name='ouput'))\n",
    "model.summary()\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "#rmsprop = RMSprop()\n",
    "model.compile(loss='mean_squared_error', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model pretrained\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Lambda, Dense, Activation, Flatten, Dropout\n",
    "#from keras.layers.convolutional import Cropping2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers import GRU, LSTM, Conv2D, ConvLSTM2D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "print(\"\\nBuilding and compiling the model ...\")\n",
    "\n",
    "# import VGG\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_tensor=None, \n",
    "            input_shape=(rows, cols, 3), classes=1000)\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg.layers])\n",
    "\n",
    "cnn_model = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block5_pool\").output)\n",
    "\n",
    "# develop a combined model\n",
    "rcnn_model = Sequential()\n",
    "rcnn_model.add(TimeDistributed(cnn_model, input_shape=(None, 160, 320, 3)))\n",
    "\n",
    "rcnn_model.add(ConvLSTM2D(256, (5, 10), strides=(1, 1), activation='relu', recurrent_activation='relu', kernel_initializer='glorot_uniform',\n",
    "               recurrent_initializer='glorot_uniform', padding='valid', return_sequences=False, name='convlstm'))\n",
    "rcnn_model.add(Flatten(name='flat'))\n",
    "rcnn_model.add(Dense(1, name='output'))\n",
    "\n",
    "for layer in cnn_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "rcnn_model.summary()\n",
    "\n",
    "adam = Adam(lr=0.01)\n",
    "#rmsprop = RMSprop()\n",
    "rcnn_model.compile(loss='mean_squared_error', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import math\n",
    "\n",
    "class LifeCycleCallBack(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        print('Beginning training')\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        print('Ending Training')\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 250\n",
    "        \n",
    "lifecycle_callback = LifeCycleCallBack()\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='../../data/logs/speed_cnn_rnn/', histogram_freq=1, \n",
    "                                          write_graph=True, write_images=True)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"../../data/weights/speed_cnn_rnn/model.h5\", monitor='val_loss', verbose=0, \n",
    "                                             save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "train_generator = data_generator(DATASET_PATH, train_set, seq_len)\n",
    "valid_generator = data_generator(VAL_PATH, valid_set, seq_len)\n",
    "\n",
    "steps_per_epoch = math.ceil((len(train_set) - seq_len)/(seq_len*BATCH_SIZE))\n",
    "validation_steps = math.ceil((len(valid_set) - seq_len)/(seq_len*BATCH_SIZE))\n",
    "\n",
    "print(\"\\nSaving Model...\")\n",
    "\n",
    "model_json = rcnn_model.to_json()\n",
    "with open(\"../../data/weights/speed_cnn_rnn/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#model.save_weights(\"model.h5\")\n",
    "print(\"Model Saved.\")\n",
    "\n",
    "\n",
    "history = rcnn_model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_steps=validation_steps,\n",
    "                              epochs=NUM_EPOCHS, verbose=1, \n",
    "                              callbacks=[lifecycle_callback, checkpoint])\n",
    "\n",
    "print(\"\\nTraining the model ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
